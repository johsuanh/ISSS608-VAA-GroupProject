[
  {
    "objectID": "ShinyApp/data/Import by html/Import by html_v2.html",
    "href": "ShinyApp/data/Import by html/Import by html_v2.html",
    "title": "import data",
    "section": "",
    "text": "pacman::p_load(rvest,dplyr,stringr,purrr,readr,httr,tidyr,fs,janitor,tidyverse,knitr)\n\n\n# Set the data folder path\ndata_folder &lt;- \"data\"\n\n# Weather stations and their corresponding SXXX codes\nstations &lt;- c(\"Changi\" = \"S24\", \"Marina_Barrage\" = \"S108\", \"Ang_Mo_Kio\" = \"S109\",\n              \"Clementi\" = \"S50\", \"Jurong_West\" = \"S44\", \"Paya_Lebar\" = \"S06\",\n              \"Newton\" = \"S111\", \"Pasir_Panjang\" = \"S116\", \"Tai_Seng\" = \"S43\",\n              \"Admiralty\" = \"S104\")\n\n# Define the range of years and months to check (January 2019 to January 2025)\nyears &lt;- 2019:2025\nmonths &lt;- sprintf(\"%02d\", 1:12)  # Format as 01, 02, ..., 12\n\n# Generate the complete list of expected files\nexpected_files &lt;- expand.grid(Station = names(stations), Year = years, Month = months, stringsAsFactors = FALSE) %&gt;%\n  filter(!(Year == 2019 & Month &lt; \"01\"),  # Exclude months before January 2019\n         !(Year == 2025 & Month &gt; \"01\"))  # Exclude months after January 2025\n\n# Generate the correct file name format (DAILYDATA_SXXX_YYYYMM.csv)\nexpected_files &lt;- expected_files %&gt;%\n  mutate(File_Code = stations[Station],  # Get the corresponding SXXX code\n         File_Name = paste0(\"DAILYDATA_\", File_Code, \"_\", Year, Month, \".csv\"),\n         File_Path = file.path(data_folder, File_Name))\n\n# Get the list of actually downloaded files\ndownloaded_files &lt;- dir_ls(data_folder, glob = \"*.csv\") %&gt;% basename()\n\n# Mark which files have been downloaded\nexpected_files &lt;- expected_files %&gt;%\n  mutate(Downloaded = File_Name %in% downloaded_files)\n\n# Summarize the download status\nsummary_table &lt;- expected_files %&gt;%\n  group_by(Station) %&gt;%\n  summarise(\n    Total_Expected = n(),\n    Downloaded = sum(Downloaded),\n    Missing = Total_Expected - Downloaded\n  )\n\n# Identify missing files\nmissing_files &lt;- expected_files %&gt;%\n  filter(!Downloaded) %&gt;%\n  select(Station, Year, Month, File_Name)\n\n# Print the list of missing files if any\nif (nrow(missing_files) &gt; 0) {\n  print(\"🚨 List of missing files:\")\n  print(missing_files)\n} else {\n  cat(\"🎉 All data downloaded successfully, no missing files!\\n\")\n}\n\n🎉 All data downloaded successfully, no missing files!\n\n# Display data download statistics\nprint(\"📊 Data download statistics:\")\n\n[1] \"📊 Data download statistics:\"\n\nprint(summary_table)\n\n# A tibble: 10 × 4\n   Station        Total_Expected Downloaded Missing\n   &lt;chr&gt;                   &lt;int&gt;      &lt;int&gt;   &lt;int&gt;\n 1 Admiralty                  73         73       0\n 2 Ang_Mo_Kio                 73         73       0\n 3 Changi                     73         73       0\n 4 Clementi                   73         73       0\n 5 Jurong_West                73         73       0\n 6 Marina_Barrage             73         73       0\n 7 Newton                     73         73       0\n 8 Pasir_Panjang              73         73       0\n 9 Paya_Lebar                 73         73       0\n10 Tai_Seng                   73         73       0\n\n\n\npacman::p_load(tidyverse,fs,janitor,knitr)\n\nfiles &lt;- fs::dir_ls(\"data/\") \n\n# Read all files and clean the column names\naws &lt;- files %&gt;%\n  map_df(~ read_csv(.x, \n                    locale = locale(encoding = \"latin1\"),\n                    col_types = cols(.default = \"character\")\n  ) %&gt;% \n    janitor::clean_names()\n  ) \n# Save the Output\nwrite.csv(aws, \"Singapore_daily_records.csv\", row.names = FALSE)"
  },
  {
    "objectID": "Team/Project_Proposal.html",
    "href": "Team/Project_Proposal.html",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "",
    "text": "In recent years, the increasing frequency of extreme weather events worldwide has raised concerns about similar trends emerging in Singapore. As a densely populated tropical city-state, Singapore may be particularly vulnerable to shifts in temperature, rainfall intensity, and other climate related changes.\nTo investigate these patterns, we are developing an interactive R Shiny dashboard that enables exploratory data analysis (EDA) and forecasting based on historical weather data from 9 AWS stations across Singapore. Through intuitive visualizations and modeling, the Shiny App dashborard empowers users to explore local weather trends and gain insights into Singapore’s evolving climate."
  },
  {
    "objectID": "Team/Project_Proposal.html#exploratory-data-analysis",
    "href": "Team/Project_Proposal.html#exploratory-data-analysis",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.1 Exploratory Data Analysis",
    "text": "4.1 Exploratory Data Analysis\nThrough an interactive Shiny App visualization, users can analyze weather patterns and explore relationships between weather factors and geographical features.\nThe following visualization methods will be used in our exploratory data analysis:\n\nLine Chart: Visualize daily, weekly, and monthly weather trends by station over time.\n\nSeasonal Monsoon Patterns: Highlight the Northeast Monsoon (Dec–Mar) and Southwest Monsoon (Jun–Sep) periods using distinct colors, allowing users to observe seasonal weather differences influenced by the monsoons.\n\nRidge Plot + Box Plot: Show the distribution of monthly weather variations by station. The users can observe weather difference of stations and cross stations directly.\nGeofacet: Display a line chart of weather data based on station coordinates, allowing users to observe how different locations may influence weather patterns.\n\n\n\nIsohyet Map: Visualize weather patterns using the tmap and gstat packages to create an Isohyet map through spatial interpolation. This tab allows users to apply two interpolation methods (IDW and Ordinary Kriging) to generate the map."
  },
  {
    "objectID": "Team/Project_Proposal.html#time-series-analysis",
    "href": "Team/Project_Proposal.html#time-series-analysis",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.2 Time Series Analysis  ",
    "text": "4.2 Time Series Analysis  \nThis section allows users to analyze weather data through STL decomposition and correlograms, helping them gain deeper insights into underlying patterns and structures in the data.\n\nTime Series Decomposition\n\nSTL Decomposition: Separates the time series into seasonal, trend, and remainder components.\nCycle Plot: Highlights recurring seasonal patterns across different periods.\n\n\n\nCorrelograms\n\nACF (Autocorrelation Function):\nMeasures the correlation between the time series and its own lagged values. It helps identify the presence of repeating patterns or seasonality and can indicate whether differencing is needed to achieve stationarity.\nPACF (Partial Autocorrelation Function):\nShows the correlation between the time series and its lagged values after removing the effects of shorter lags. It is especially useful for determining the appropriate number of lags in autoregressive (AR) models.\nDifferencing Analysis:\nIncludes both trend differencing (removing long-term trends) and seasonal differencing (removing seasonal effects) to help transform the time series into a stationary format, which is often required for effective forecasting using models like ARIMA."
  },
  {
    "objectID": "Team/Project_Proposal.html#univariate-forecasting",
    "href": "Team/Project_Proposal.html#univariate-forecasting",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.3 Univariate Forecasting",
    "text": "4.3 Univariate Forecasting\nThis section allows users to select a variable of interest for time series forecasting. We provide a variety of models, including:\n\nETS-ANN: Simple Exponential Smoothing\nETS-AAN: Holt’s Linear Trend\nETS-AAA: Holt-Winters Additive\nETS-MMM: Holt-Winters Multiplicative\nETS-MAM: Multiplicative Holt-Winters with Additive Trend\nETS-MMN: Multiplicative Trend Exponential Smoothing\nAuto ARIMA\nAuto ETS\n\n\nModel Training\nThe train-test split is set at 80% vs 20%. This tab allows users to select, train, test, and evaluate models using metrics such as AIC, BIC, and RMSE. Residual plots are also provided to help assess model performance and adequacy.\n\n\nModel Forecasting\nAfter reviewing model training performance, users can select their preferred models for forecasting. The selected models will generate future predictions, and key model parameters will be displayed for reference."
  },
  {
    "objectID": "Team/Project_Proposal.html#eda-prototype",
    "href": "Team/Project_Proposal.html#eda-prototype",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "6-1 EDA Prototype:",
    "text": "6-1 EDA Prototype:\n\nLine ChartRidge Plot + Box PlotGeofacetIsohyet Map"
  },
  {
    "objectID": "Team/Project_Proposal.html#time-series-analysis-prototype",
    "href": "Team/Project_Proposal.html#time-series-analysis-prototype",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "6-2 Time Series Analysis Prototype:",
    "text": "6-2 Time Series Analysis Prototype:\n\nTime Series DecompositionCorrleograms"
  },
  {
    "objectID": "Team/Project_Proposal.html#univariate-forecasting-prototype",
    "href": "Team/Project_Proposal.html#univariate-forecasting-prototype",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "6-3 Univariate Forecasting Prototype:",
    "text": "6-3 Univariate Forecasting Prototype:\n\nModel TrainingModel Forecasting"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#review-the-data-structure",
    "href": "ShinyApp/Data_Preparation.html#review-the-data-structure",
    "title": "Weather Data Preparation",
    "section": "3.1 Review the data structure",
    "text": "3.1 Review the data structure\nThere are 22,230 observations in the weather data, including 10 AWS stations and 5 years’ records.\nAs shown in the table below, several variables have incorrect data formats. Transformations need to be made for these variables:\n\nstation should be a factor type\nrainfall, temperature, and wind speed should be numeric types\nhighest 30, 60 and 90 mm rainfall columns contain character “\\u0997”, which should be replaced by NA\n\n\nstr(station)\n\nspc_tbl_ [22,230 × 16] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ station                    : chr [1:22230] \"Paya Lebar\" \"Paya Lebar\" \"Paya Lebar\" \"Paya Lebar\" ...\n $ year                       : num [1:22230] 2019 2019 2019 2019 2019 ...\n $ month                      : num [1:22230] 1 1 1 1 1 1 1 1 1 1 ...\n $ day                        : num [1:22230] 1 2 3 4 5 6 7 8 9 10 ...\n $ daily_rainfall_total_mm    : chr [1:22230] \"0\" \"0\" \"0\" \"0\" ...\n $ highest_30_min_rainfall_mm : chr [1:22230] \"\\u0097\" \"\\u0097\" \"\\u0097\" \"\\u0097\" ...\n $ highest_60_min_rainfall_mm : chr [1:22230] \"\\u0097\" \"\\u0097\" \"\\u0097\" \"\\u0097\" ...\n $ highest_120_min_rainfall_mm: chr [1:22230] \"\\u0097\" \"\\u0097\" \"\\u0097\" \"\\u0097\" ...\n $ mean_temperature_c         : chr [1:22230] \"29.5\" \"30\" \"30.3\" \"30.4\" ...\n $ maximum_temperature_c      : chr [1:22230] \"34.2\" \"33.8\" \"33.1\" \"33.5\" ...\n $ minimum_temperature_c      : chr [1:22230] \"26.1\" \"25.8\" \"26.7\" \"26.9\" ...\n $ mean_wind_speed_km_h       : chr [1:22230] \"11.9\" \"13\" \"15.8\" \"11.2\" ...\n $ max_wind_speed_km_h        : chr [1:22230] \"42.5\" \"46.4\" \"48.2\" \"35.3\" ...\n $ mean_temperature_a_c       : chr [1:22230] NA NA NA NA ...\n $ maximum_temperature_a_c    : chr [1:22230] NA NA NA NA ...\n $ minimum_temperature_a_c    : chr [1:22230] NA NA NA NA ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   station = col_character(),\n  ..   year = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   daily_rainfall_total_mm = col_character(),\n  ..   highest_30_min_rainfall_mm = col_character(),\n  ..   highest_60_min_rainfall_mm = col_character(),\n  ..   highest_120_min_rainfall_mm = col_character(),\n  ..   mean_temperature_c = col_character(),\n  ..   maximum_temperature_c = col_character(),\n  ..   minimum_temperature_c = col_character(),\n  ..   mean_wind_speed_km_h = col_character(),\n  ..   max_wind_speed_km_h = col_character(),\n  ..   mean_temperature_a_c = col_character(),\n  ..   maximum_temperature_a_c = col_character(),\n  ..   minimum_temperature_a_c = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#handle-incorrect-data-format",
    "href": "ShinyApp/Data_Preparation.html#handle-incorrect-data-format",
    "title": "Weather Data Preparation",
    "section": "3.2 Handle Incorrect Data Format",
    "text": "3.2 Handle Incorrect Data Format\nThe code chunk below is performed to address the data issues mentioned earlier:\n\nstation &lt;- station %&gt;%\n  mutate(across(\n    c(highest_30_min_rainfall_mm, highest_60_min_rainfall_mm, highest_120_min_rainfall_mm,\n      daily_rainfall_total_mm, mean_temperature_c, maximum_temperature_c, \n      minimum_temperature_c, mean_wind_speed_km_h, max_wind_speed_km_h,mean_temperature_a_c,\n      maximum_temperature_a_c,minimum_temperature_a_c),\n    ~ as.numeric(gsub(\"\\u0097\", NA, .))\n  )) %&gt;%\n  mutate(station = as.factor(station))"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#add-date-and-week-no.",
    "href": "ShinyApp/Data_Preparation.html#add-date-and-week-no.",
    "title": "Weather Data Preparation",
    "section": "3.3 Add Date and Week No.",
    "text": "3.3 Add Date and Week No.\nAs the weather data is a time-series data, it’s necessary to add date information for further data analysis. The lubridate package is used for creating date and weekday columns:\n\nstation &lt;- station %&gt;%\n  mutate(date = ymd(paste(year, month, day, sep = \"-\")),\n         Week_no = week(date))\n\n# if Week_no =53, revise it to 52\nstation &lt;- station %&gt;%\n  mutate(Week_no = ifelse(Week_no == 53, 52, Week_no))"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#handle-missing-values",
    "href": "ShinyApp/Data_Preparation.html#handle-missing-values",
    "title": "Weather Data Preparation",
    "section": "3.4 Handle Missing Values",
    "text": "3.4 Handle Missing Values\nLet’s check the data summary and missing values:\nExcept for columns “station”, “year”, “month” and “day”, other columns contain lots of missing values, especially for temperature data (*_temperature_c and *_temperature_a_c) with over 17K and 6K missing values.\n\nsummary(station)\n\n           station          year          month             day       \n Admiralty     :2223   Min.   :2019   Min.   : 1.000   Min.   : 1.00  \n Ang Mo Kio    :2223   1st Qu.:2020   1st Qu.: 3.000   1st Qu.: 8.00  \n Changi        :2223   Median :2022   Median : 6.000   Median :16.00  \n Clementi      :2223   Mean   :2022   Mean   : 6.445   Mean   :15.74  \n Jurong (West) :2223   3rd Qu.:2023   3rd Qu.: 9.000   3rd Qu.:23.00  \n Marina Barrage:2223   Max.   :2025   Max.   :12.000   Max.   :31.00  \n (Other)       :8892                                                  \n daily_rainfall_total_mm highest_30_min_rainfall_mm highest_60_min_rainfall_mm\n Min.   :  0.000         Min.   : 0.000             Min.   :  0.000           \n 1st Qu.:  0.000         1st Qu.: 0.000             1st Qu.:  0.000           \n Median :  0.200         Median : 0.200             Median :  0.200           \n Mean   :  7.083         Mean   : 4.011             Mean   :  5.042           \n 3rd Qu.:  6.800         3rd Qu.: 4.400             3rd Qu.:  5.000           \n Max.   :210.600         Max.   :65.600             Max.   :102.600           \n NA's   :278             NA's   :1018               NA's   :1027              \n highest_120_min_rainfall_mm mean_temperature_c maximum_temperature_c\n Min.   :  0.000             Min.   :23.40      Min.   :24.80        \n 1st Qu.:  0.000             1st Qu.:27.60      1st Qu.:31.40        \n Median :  0.200             Median :28.40      Median :32.40        \n Mean   :  5.832             Mean   :28.31      Mean   :32.24        \n 3rd Qu.:  5.800             3rd Qu.:29.10      3rd Qu.:33.30        \n Max.   :119.800             Max.   :31.70      Max.   :36.40        \n NA's   :1027                NA's   :17484      NA's   :17473        \n minimum_temperature_c mean_wind_speed_km_h max_wind_speed_km_h\n Min.   :21.10         Min.   : 0.400       Min.   : 8.30      \n 1st Qu.:24.90         1st Qu.: 5.900       1st Qu.:27.80      \n Median :25.80         Median : 7.900       Median :32.80      \n Mean   :25.74         Mean   : 8.843       Mean   :33.95      \n 3rd Qu.:26.80         3rd Qu.:10.800       3rd Qu.:38.90      \n Max.   :29.10         Max.   :28.800       Max.   :97.60      \n NA's   :17473         NA's   :1092         NA's   :968        \n mean_temperature_a_c maximum_temperature_a_c minimum_temperature_a_c\n Min.   :22.50        Min.   :23.70           Min.   :20.40          \n 1st Qu.:27.10        1st Qu.:30.90           1st Qu.:24.30          \n Median :28.00        Median :32.10           Median :25.30          \n Mean   :27.99        Mean   :31.85           Mean   :25.35          \n 3rd Qu.:28.90        3rd Qu.:33.10           3rd Qu.:26.40          \n Max.   :31.30        Max.   :37.00           Max.   :29.50          \n NA's   :6172         NA's   :6104            NA's   :6107           \n      date               Week_no     \n Min.   :2019-01-01   Min.   : 1.00  \n 1st Qu.:2020-07-09   1st Qu.:13.00  \n Median :2022-01-16   Median :26.00  \n Mean   :2022-01-16   Mean   :26.26  \n 3rd Qu.:2023-07-26   3rd Qu.:39.00  \n Max.   :2025-01-31   Max.   :52.00  \n                                     \n\n\n\nkable(data.frame(Column = names(station), NAs = colSums(is.na(station))))\n\n\n\n\n\nColumn\nNAs\n\n\n\n\nstation\nstation\n0\n\n\nyear\nyear\n0\n\n\nmonth\nmonth\n0\n\n\nday\nday\n0\n\n\ndaily_rainfall_total_mm\ndaily_rainfall_total_mm\n278\n\n\nhighest_30_min_rainfall_mm\nhighest_30_min_rainfall_mm\n1018\n\n\nhighest_60_min_rainfall_mm\nhighest_60_min_rainfall_mm\n1027\n\n\nhighest_120_min_rainfall_mm\nhighest_120_min_rainfall_mm\n1027\n\n\nmean_temperature_c\nmean_temperature_c\n17484\n\n\nmaximum_temperature_c\nmaximum_temperature_c\n17473\n\n\nminimum_temperature_c\nminimum_temperature_c\n17473\n\n\nmean_wind_speed_km_h\nmean_wind_speed_km_h\n1092\n\n\nmax_wind_speed_km_h\nmax_wind_speed_km_h\n968\n\n\nmean_temperature_a_c\nmean_temperature_a_c\n6172\n\n\nmaximum_temperature_a_c\nmaximum_temperature_a_c\n6104\n\n\nminimum_temperature_a_c\nminimum_temperature_a_c\n6107\n\n\ndate\ndate\n0\n\n\nWeek_no\nWeek_no\n0\n\n\n\n\n\n\n3.4.1 Missing Temperature_c and Temperature_a_c\nHowever, upon closer inspection of the missing values, we discovered that the columns were switched: missing temperature_c values appeared in temperature_a_c, and vice versa. To maintain data integrity, we will use the coalesce() function to combine these values into the temperature_c column.\n\nmissing temperature_cmissing temperature_a_c\n\n\nThe table below shows records with missing values in mean_temperature_c\n\nstation_filtered_c &lt;- station %&gt;%\n  filter(is.na(mean_temperature_c))\n\nkable(head(station_filtered_c,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstation\nyear\nmonth\nday\ndaily_rainfall_total_mm\nhighest_30_min_rainfall_mm\nhighest_60_min_rainfall_mm\nhighest_120_min_rainfall_mm\nmean_temperature_c\nmaximum_temperature_c\nminimum_temperature_c\nmean_wind_speed_km_h\nmax_wind_speed_km_h\nmean_temperature_a_c\nmaximum_temperature_a_c\nminimum_temperature_a_c\ndate\nWeek_no\n\n\n\n\nPaya Lebar\n2020\n4\n1\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n6.8\n25.9\n30.1\n34.2\n27.0\n2020-04-01\n14\n\n\nPaya Lebar\n2020\n4\n2\n54.3\nNA\nNA\nNA\nNA\nNA\nNA\n6.8\n33.3\n29.1\n35.6\n25.4\n2020-04-02\n14\n\n\nPaya Lebar\n2020\n4\n3\n20.7\nNA\nNA\nNA\nNA\nNA\nNA\n7.8\n33.3\n28.9\n33.8\n24.2\n2020-04-03\n14\n\n\nPaya Lebar\n2020\n4\n4\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n9.6\n33.3\n30.3\n35.2\n27.0\n2020-04-04\n14\n\n\nPaya Lebar\n2020\n4\n5\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n7.1\n29.6\n29.9\n34.2\n27.1\n2020-04-05\n14\n\n\nPaya Lebar\n2020\n4\n6\n0.7\nNA\nNA\nNA\nNA\nNA\nNA\n5.9\n27.8\n29.4\n32.5\n24.0\n2020-04-06\n14\n\n\nPaya Lebar\n2020\n4\n7\n27.4\nNA\nNA\nNA\nNA\nNA\nNA\n5.7\n24.1\n28.7\n33.9\n24.0\n2020-04-07\n14\n\n\nPaya Lebar\n2020\n4\n8\n8.9\nNA\nNA\nNA\nNA\nNA\nNA\n6.7\n35.2\n28.7\n34.8\n24.8\n2020-04-08\n15\n\n\nPaya Lebar\n2020\n4\n9\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n7.9\n31.5\n29.7\n35.0\n25.7\n2020-04-09\n15\n\n\nPaya Lebar\n2020\n4\n10\n0.0\nNA\nNA\nNA\nNA\nNA\nNA\n6.6\n22.2\n29.8\n34.5\n26.1\n2020-04-10\n15\n\n\n\n\n\n\n\nThe table below shows records with missing values in mean_temperature_a_c\n\nstation_filtered_a_c &lt;- station %&gt;%\n  filter(is.na(mean_temperature_a_c))\n\nkable(head(station_filtered_a_c,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstation\nyear\nmonth\nday\ndaily_rainfall_total_mm\nhighest_30_min_rainfall_mm\nhighest_60_min_rainfall_mm\nhighest_120_min_rainfall_mm\nmean_temperature_c\nmaximum_temperature_c\nminimum_temperature_c\nmean_wind_speed_km_h\nmax_wind_speed_km_h\nmean_temperature_a_c\nmaximum_temperature_a_c\nminimum_temperature_a_c\ndate\nWeek_no\n\n\n\n\nPaya Lebar\n2019\n1\n1\n0.0\nNA\nNA\nNA\n29.5\n34.2\n26.1\n11.9\n42.5\nNA\nNA\nNA\n2019-01-01\n1\n\n\nPaya Lebar\n2019\n1\n2\n0.0\nNA\nNA\nNA\n30.0\n33.8\n25.8\n13.0\n46.4\nNA\nNA\nNA\n2019-01-02\n1\n\n\nPaya Lebar\n2019\n1\n3\n0.0\nNA\nNA\nNA\n30.3\n33.1\n26.7\n15.8\n48.2\nNA\nNA\nNA\n2019-01-03\n1\n\n\nPaya Lebar\n2019\n1\n4\n0.0\nNA\nNA\nNA\n30.4\n33.5\n26.9\n11.2\n35.3\nNA\nNA\nNA\n2019-01-04\n1\n\n\nPaya Lebar\n2019\n1\n5\n6.2\nNA\nNA\nNA\n29.0\n34.0\n26.0\n7.2\n31.3\nNA\nNA\nNA\n2019-01-05\n1\n\n\nPaya Lebar\n2019\n1\n6\n0.0\nNA\nNA\nNA\n29.1\n32.7\n26.2\n15.8\n38.9\nNA\nNA\nNA\n2019-01-06\n1\n\n\nPaya Lebar\n2019\n1\n7\n0.0\nNA\nNA\nNA\n29.4\n33.1\n26.0\n16.6\n42.5\nNA\nNA\nNA\n2019-01-07\n1\n\n\nPaya Lebar\n2019\n1\n8\n14.9\nNA\nNA\nNA\n28.6\n31.6\n26.0\n12.6\n33.5\nNA\nNA\nNA\n2019-01-08\n2\n\n\nPaya Lebar\n2019\n1\n9\n0.0\nNA\nNA\nNA\n29.1\n32.7\n25.8\n16.9\n42.5\nNA\nNA\nNA\n2019-01-09\n2\n\n\nPaya Lebar\n2019\n1\n10\n0.0\nNA\nNA\nNA\n29.2\n33.0\n25.3\n16.6\n42.5\nNA\nNA\nNA\n2019-01-10\n2\n\n\n\n\n\n\n\n\n\n\n3.4.2 Coalesce Temperature Data\nThe coalesce function combines values from min, max, and mean temperature columns (both temp_c and temp_a_c) to handle missing values, and remove the _a_c columns:\n\nstation$mean_temperature_c &lt;- coalesce(station$mean_temperature_c, station$mean_temperature_a_c)\nstation$maximum_temperature_c &lt;- coalesce(station$maximum_temperature_c, station$maximum_temperature_a_c)\nstation$minimum_temperature_c &lt;- coalesce(station$minimum_temperature_c, station$minimum_temperature_a_c)\n\nstation &lt;- station %&gt;% \n  select(-c(\"mean_temperature_a_c\", \n            \"maximum_temperature_a_c\", \"minimum_temperature_a_c\"))\n\nNow, let’s review the summary of missing values again. The number of missing values has dramatically decreased to 1000ish.\n\nkable(data.frame(Column = names(station), NAs = colSums(is.na(station))))\n\n\n\n\n\nColumn\nNAs\n\n\n\n\nstation\nstation\n0\n\n\nyear\nyear\n0\n\n\nmonth\nmonth\n0\n\n\nday\nday\n0\n\n\ndaily_rainfall_total_mm\ndaily_rainfall_total_mm\n278\n\n\nhighest_30_min_rainfall_mm\nhighest_30_min_rainfall_mm\n1018\n\n\nhighest_60_min_rainfall_mm\nhighest_60_min_rainfall_mm\n1027\n\n\nhighest_120_min_rainfall_mm\nhighest_120_min_rainfall_mm\n1027\n\n\nmean_temperature_c\nmean_temperature_c\n1426\n\n\nmaximum_temperature_c\nmaximum_temperature_c\n1347\n\n\nminimum_temperature_c\nminimum_temperature_c\n1350\n\n\nmean_wind_speed_km_h\nmean_wind_speed_km_h\n1092\n\n\nmax_wind_speed_km_h\nmax_wind_speed_km_h\n968\n\n\ndate\ndate\n0\n\n\nWeek_no\nWeek_no\n0\n\n\n\n\n\n\n\n3.4.3 Remove Marina Barrage Station Data and Highest Rainfall Attributes\nAs shown in the time-series plot, Marina Barrage has missing data since later half of year in 2022, since the missing value is too many, the station should be dropped\n\nggplot(station, aes(x = date, y = mean_temperature_c, color = station, group = station)) +\n  geom_line(linewidth = 1, alpha = 0.7) +\n  facet_grid(~station)+\n  coord_flip()+\n  theme_minimal() +\n  labs(title = \"Mean temperature\",\n       x = \"Date\",\n       y = \"Mean temperature (celcius degree)\") +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\n\nstation &lt;- station %&gt;% filter(station != \"Marina Barrage\")\n\nAfter removing Marina Barrage, the missing values are decreased:\n\nkable(data.frame(Column = names(station), NAs = colSums(is.na(station))))\n\n\n\n\n\nColumn\nNAs\n\n\n\n\nstation\nstation\n0\n\n\nyear\nyear\n0\n\n\nmonth\nmonth\n0\n\n\nday\nday\n0\n\n\ndaily_rainfall_total_mm\ndaily_rainfall_total_mm\n166\n\n\nhighest_30_min_rainfall_mm\nhighest_30_min_rainfall_mm\n889\n\n\nhighest_60_min_rainfall_mm\nhighest_60_min_rainfall_mm\n897\n\n\nhighest_120_min_rainfall_mm\nhighest_120_min_rainfall_mm\n897\n\n\nmean_temperature_c\nmean_temperature_c\n319\n\n\nmaximum_temperature_c\nmaximum_temperature_c\n252\n\n\nminimum_temperature_c\nminimum_temperature_c\n255\n\n\nmean_wind_speed_km_h\nmean_wind_speed_km_h\n981\n\n\nmax_wind_speed_km_h\nmax_wind_speed_km_h\n859\n\n\ndate\ndate\n0\n\n\nWeek_no\nWeek_no\n0\n\n\n\n\n\n\n\n3.4.4 Handling Remaining Missing Values\nSince the missing values are distributed throughout the dataset, and given that this is time-series weather data, removing entire rows would disrupt subsequent visualizations. To minimize analysis errors, interpolation is a more suitable approach for handling missing data.\nBelow are the methods used to address missing values for different attributes:\nTemperature Data:\n\nIf both minimum and maximum temperature values are available, the mean temperature is interpolated as their average.\nIf temperature data is entirely missing, we use the zoo package to interpolate the mean temperature using moving averages over progressively larger windows: 7 days → 15 days → 30 days.\n\nRainfall Data:\n\nIf the daily total rainfall is 0 and the highest recorded rainfall is missing, we assume the missing values are also 0.\nIf the daily total rainfall itself is missing, we apply the same moving average interpolation method as for temperature data.\n\nWind Speed Data:\n\nIf wind speed data is missing, we interpolate it using the zoo package with moving averages over progressively expanding windows: 7 days → 15 days → 30 days → 45 days → 60 days.\nAt stations with continuous missing values exceeding 30 days (Jurong West, Tai Seng, and Clementi), the moving average window is extended to 60 days to improve accuracy.\n\n\n\n\n\n\n\n\n# Step 1: Interpolate mean temperature using min and max temp\nstation &lt;- station %&gt;%\n  mutate(mean_temperature_c = ifelse(\n    is.na(mean_temperature_c) & !is.na(minimum_temperature_c) & !is.na(maximum_temperature_c),\n    round((minimum_temperature_c + maximum_temperature_c) / 2, 2),\n    mean_temperature_c\n  ))\n\n# Step 2: Define funtion for rolling mean for remaining missing values\nfill_missing_with_rollapply &lt;- function(x, window_sizes) {\n  for (w in window_sizes) {\n    missing_idx &lt;- which(is.na(x))\n    if (length(missing_idx) == 0) break  # Stop if no missing values remain\n    \n    roll_values &lt;- rollapply(x, width = w, FUN = mean, fill = NA, align = \"center\", na.rm = TRUE)\n    x[missing_idx] &lt;- ifelse(is.na(x[missing_idx]), round(roll_values[missing_idx],2), x[missing_idx])\n  }\n  return(x)\n}\n# Apply rolling mean imputation with increasing window sizes\nwindow_sizes &lt;- c(7, 15, 30, 45, 60)\nstation$mean_temperature_c &lt;- fill_missing_with_rollapply(station$mean_temperature_c, window_sizes)\nstation$minimum_temperature_c &lt;- fill_missing_with_rollapply(station$minimum_temperature_c, window_sizes)\nstation$maximum_temperature_c &lt;- fill_missing_with_rollapply(station$maximum_temperature_c, window_sizes)\nstation$mean_wind_speed_km_h &lt;- fill_missing_with_rollapply(station$mean_wind_speed_km_h, window_sizes)\nstation$max_wind_speed_km_h &lt;- fill_missing_with_rollapply(station$max_wind_speed_km_h, window_sizes)\nstation$daily_rainfall_total_mm &lt;- fill_missing_with_rollapply(station$daily_rainfall_total_mm, window_sizes)\n\n\n# Input 0 for missing highest rain fall\nstation &lt;- station %&gt;%\n  mutate(\n    highest_30_min_rainfall_mm = ifelse(daily_rainfall_total_mm == 0 & is.na(highest_30_min_rainfall_mm), 0, highest_30_min_rainfall_mm),\n    highest_60_min_rainfall_mm = ifelse(daily_rainfall_total_mm == 0 & is.na(highest_60_min_rainfall_mm), 0, highest_60_min_rainfall_mm),\n    highest_120_min_rainfall_mm = ifelse(daily_rainfall_total_mm == 0 & is.na(highest_120_min_rainfall_mm), 0, highest_120_min_rainfall_mm))\n\nstation &lt;- station %&gt;%\n  select(-c(highest_30_min_rainfall_mm, highest_60_min_rainfall_mm, highest_120_min_rainfall_mm))\n\nAfter interpolation, there are no missing values now:\n\nkable(data.frame(Column = names(station), NAs = colSums(is.na(station))))\n\n\n\n\n\nColumn\nNAs\n\n\n\n\nstation\nstation\n0\n\n\nyear\nyear\n0\n\n\nmonth\nmonth\n0\n\n\nday\nday\n0\n\n\ndaily_rainfall_total_mm\ndaily_rainfall_total_mm\n0\n\n\nmean_temperature_c\nmean_temperature_c\n0\n\n\nmaximum_temperature_c\nmaximum_temperature_c\n0\n\n\nminimum_temperature_c\nminimum_temperature_c\n0\n\n\nmean_wind_speed_km_h\nmean_wind_speed_km_h\n124\n\n\nmax_wind_speed_km_h\nmax_wind_speed_km_h\n124\n\n\ndate\ndate\n0\n\n\nWeek_no\nWeek_no\n0"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#rename-the-column",
    "href": "ShinyApp/Data_Preparation.html#rename-the-column",
    "title": "Weather Data Preparation",
    "section": "3.5 Rename the Column",
    "text": "3.5 Rename the Column\n\nstation &lt;- station %&gt;%\n  rename(`Mean Temperature` = mean_temperature_c,\n         `Min Temperature`= minimum_temperature_c,\n         `Max Temperature`= maximum_temperature_c,\n         `Rainfall` = daily_rainfall_total_mm,\n         `Mean Wind Speed` = mean_wind_speed_km_h,\n         `Max Wind Speed` = max_wind_speed_km_h)"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#generate-weekly-and-monthly-data",
    "href": "ShinyApp/Data_Preparation.html#generate-weekly-and-monthly-data",
    "title": "Weather Data Preparation",
    "section": "3.6 Generate weekly and monthly data",
    "text": "3.6 Generate weekly and monthly data\nIn the Shiny app, we will provide three time resolutions: daily, weekly, and monthly.\nTo aggregate data at the weekly and monthly levels, we will use the group_by and summarise functions to compute relevant summaries for each time period:\n\nMonthly data\n\nmonthly &lt;- station %&gt;%\n  group_by(station,year,month) %&gt;%\n  summarise(\n    `Mean Temperature` = round(mean(`Mean Temperature`, na.rm = TRUE), 1),\n    `Min Temperature` = min(`Min Temperature`, na.rm = TRUE),\n    `Max Temperature` = max(`Max Temperature`, na.rm = TRUE),\n    `Rainfall` = round(sum(`Rainfall`, na.rm = TRUE),1),\n    `Mean Wind Speed` = round(mean(`Mean Wind Speed`, na.rm=TRUE),1),\n    `Max Wind Speed` = max(`Max Wind Speed`, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nmonthly &lt;- monthly %&gt;%\n  mutate(date = ymd(paste(year, month, 1, sep = \"-\")),\n         `Max Wind Speed` = ifelse(`Max Wind Speed` == -Inf, NA, `Max Wind Speed`))\n\nWeekly data\n\nweekly &lt;- station %&gt;%\n  group_by(station,year,month,Week_no) %&gt;%\n  summarise(\n    `Mean Temperature` = round(mean(`Mean Temperature`, na.rm = TRUE), 1),\n    `Min Temperature` = min(`Min Temperature`, na.rm = TRUE),\n    `Max Temperature` = max(`Max Temperature`, na.rm = TRUE),\n    `Rainfall` = round(sum(`Rainfall`, na.rm = TRUE),1),\n    `Mean Wind Speed` = round(mean(`Mean Wind Speed`, na.rm=TRUE),1),\n    `Max Wind Speed` = max(`Max Wind Speed`, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nweekly &lt;- weekly %&gt;%\n  mutate(date = as.Date(paste(year, Week_no, 1), format = \"%Y %U %u\"),\n         `Max Wind Speed` = ifelse(`Max Wind Speed` == -Inf, NA, `Max Wind Speed`))"
  },
  {
    "objectID": "ShinyApp/Data_Preparation.html#save-the-files-as-rds",
    "href": "ShinyApp/Data_Preparation.html#save-the-files-as-rds",
    "title": "Weather Data Preparation",
    "section": "3.7 Save the files as RDS",
    "text": "3.7 Save the files as RDS\n\nsaveRDS(station, \"data/station_daily_data.rds\")\nsaveRDS(weekly, \"data/station_weekly_data.rds\")\nsaveRDS(monthly, \"data/station_monthly_data.rds\")"
  },
  {
    "objectID": "ShinyApp/data/Import by html/check rds data.html",
    "href": "ShinyApp/data/Import by html/check rds data.html",
    "title": "test rds data",
    "section": "",
    "text": "pacman::p_load(shiny, shinydashboard, highcharter, leaflet, bslib, yaml, bsicons,dplyr)\n\n\ngetwd()\n\n[1] \"/Users/johsuan/johsuanh/ISSS608-VAA-GroupProject/ShinyApp/data/Import by html\""
  },
  {
    "objectID": "ShinyApp/data/Import by html/Import by html.html",
    "href": "ShinyApp/data/Import by html/Import by html.html",
    "title": "import data",
    "section": "",
    "text": "pacman::p_load(rvest,dplyr,stringr,purrr,readr,httr,tidyr,fs,janitor,tidyverse,knitr)\n\n\n# Set the data folder path\ndata_folder &lt;- \"data\"\n\n# Weather stations and their corresponding SXXX codes\nstations &lt;- c(\"Changi\" = \"S24\", \"Marina_Barrage\" = \"S108\", \"Ang_Mo_Kio\" = \"S109\",\n              \"Clementi\" = \"S50\", \"Jurong_West\" = \"S44\", \"Paya_Lebar\" = \"S06\",\n              \"Newton\" = \"S111\", \"Pasir_Panjang\" = \"S116\", \"Tai_Seng\" = \"S43\",\n              \"Admiralty\" = \"S104\")\n\n# Define the range of years and months to check (January 2019 to January 2025)\nyears &lt;- 2019:2025\nmonths &lt;- sprintf(\"%02d\", 1:12)  # Format as 01, 02, ..., 12\n\n# Generate the complete list of expected files\nexpected_files &lt;- expand.grid(Station = names(stations), Year = years, Month = months, stringsAsFactors = FALSE) %&gt;%\n  filter(!(Year == 2019 & Month &lt; \"01\"),  # Exclude months before January 2019\n         !(Year == 2025 & Month &gt; \"01\"))  # Exclude months after January 2025\n\n# Generate the correct file name format (DAILYDATA_SXXX_YYYYMM.csv)\nexpected_files &lt;- expected_files %&gt;%\n  mutate(File_Code = stations[Station],  # Get the corresponding SXXX code\n         File_Name = paste0(\"DAILYDATA_\", File_Code, \"_\", Year, Month, \".csv\"),\n         File_Path = file.path(data_folder, File_Name))\n\n# Get the list of actually downloaded files\ndownloaded_files &lt;- dir_ls(data_folder, glob = \"*.csv\") %&gt;% basename()\n\n# Mark which files have been downloaded\nexpected_files &lt;- expected_files %&gt;%\n  mutate(Downloaded = File_Name %in% downloaded_files)\n\n# Summarize the download status\nsummary_table &lt;- expected_files %&gt;%\n  group_by(Station) %&gt;%\n  summarise(\n    Total_Expected = n(),\n    Downloaded = sum(Downloaded),\n    Missing = Total_Expected - Downloaded\n  )\n\n# Identify missing files\nmissing_files &lt;- expected_files %&gt;%\n  filter(!Downloaded) %&gt;%\n  select(Station, Year, Month, File_Name)\n\n# Print the list of missing files if any\nif (nrow(missing_files) &gt; 0) {\n  print(\"🚨 List of missing files:\")\n  print(missing_files)\n} else {\n  cat(\"🎉 All data downloaded successfully, no missing files!\\n\")\n}\n\n🎉 All data downloaded successfully, no missing files!\n\n# Display data download statistics\nprint(\"📊 Data download statistics:\")\n\n[1] \"📊 Data download statistics:\"\n\nprint(summary_table)\n\n# A tibble: 10 × 4\n   Station        Total_Expected Downloaded Missing\n   &lt;chr&gt;                   &lt;int&gt;      &lt;int&gt;   &lt;int&gt;\n 1 Admiralty                  73         73       0\n 2 Ang_Mo_Kio                 73         73       0\n 3 Changi                     73         73       0\n 4 Clementi                   73         73       0\n 5 Jurong_West                73         73       0\n 6 Marina_Barrage             73         73       0\n 7 Newton                     73         73       0\n 8 Pasir_Panjang              73         73       0\n 9 Paya_Lebar                 73         73       0\n10 Tai_Seng                   73         73       0\n\n\n\n# Set the data folder path\ndata_folder &lt;- \"data\"\n\n# Get the list of all CSV files\nfilenames &lt;- dir_ls(data_folder, glob = \"*.csv\")\n\n# Read all files, fix encoding, standardize column names, and remove duplicate columns\ncombined_data &lt;- filenames %&gt;%\n  map_df(~ read_csv(.x, \n                    locale = locale(encoding = \"latin1\"),  # Handle encoding issues\n                    col_types = cols(.default = \"character\"))  # Read all columns as character type initially\n  ) %&gt;%\n  janitor::clean_names()  # Standardize column names format\n\n# Select only the required columns\nselected_columns &lt;- c(\"station\", \"year\", \"month\", \"day\",\n                      \"daily_rainfall_total_mm\", \"highest_30_min_rainfall_mm\",\n                      \"highest_60_min_rainfall_mm\", \"highest_120_min_rainfall_mm\",\n                      \"mean_temperature_c\", \"maximum_temperature_c\",\n                      \"minimum_temperature_c\",\n                      \"mean_wind_speed_km_h\",\n                      \"max_wind_speed_km_h\")\n\n# Ensure the data contains only these columns and remove extra columns\ncombined_data &lt;- combined_data %&gt;%\n  select(any_of(selected_columns))  # `any_of()` prevents errors even if some columns are missing\n\n# Remove rows where 'station' is NA\ncombined_data &lt;- combined_data %&gt;%\n  filter(!is.na(station) & station != \"\")  # Remove NA and empty station names\n\n# Convert numeric columns to numeric type and clean missing values\nnumeric_cols &lt;- selected_columns[5:length(selected_columns)]  # Select numeric columns\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(across(all_of(numeric_cols), ~ as.numeric(str_replace(.x, \"[^0-9.-]\", \"\")), .names = \"clean_{.col}\")) %&gt;% # Clean data first\n  select(-all_of(numeric_cols)) %&gt;%  # Remove original columns\n  rename_with(~ str_remove(.x, \"clean_\"))  # Restore original column names\n\nWarning: There were 6 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(...)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 5 remaining warnings.\n\n# Save the merged dataset\nwrite_csv(combined_data, file = \"data/Singapore_daily_records.csv\")\n\n# Display data preview\nprint(\"✅ The merge is complete! Saved as: `Singapore_daily_records.csv`\")\n\n[1] \"✅ The merge is complete! Saved as: `Singapore_daily_records.csv`\"\n\nglimpse(combined_data)\n\nRows: 22,230\nColumns: 13\n$ station                     &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\", …\n$ year                        &lt;chr&gt; \"2019\", \"2019\", \"2019\", \"2019\", \"2019\", \"2…\n$ month                       &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ day                         &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9…\n$ daily_rainfall_total_mm     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 6.2, 0.0, 0.0, 14.9, 0…\n$ highest_30_min_rainfall_mm  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ highest_60_min_rainfall_mm  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ highest_120_min_rainfall_mm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ mean_temperature_c          &lt;dbl&gt; 29.5, 30.0, 30.3, 30.4, 29.0, 29.1, 29.4, …\n$ maximum_temperature_c       &lt;dbl&gt; 34.2, 33.8, 33.1, 33.5, 34.0, 32.7, 33.1, …\n$ minimum_temperature_c       &lt;dbl&gt; 26.1, 25.8, 26.7, 26.9, 26.0, 26.2, 26.0, …\n$ mean_wind_speed_km_h        &lt;dbl&gt; 11.9, 13.0, 15.8, 11.2, 7.2, 15.8, 16.6, 1…\n$ max_wind_speed_km_h         &lt;dbl&gt; 42.5, 46.4, 48.2, 35.3, 31.3, 38.9, 42.5, …"
  },
  {
    "objectID": "ShinyApp/User_Guide.html",
    "href": "ShinyApp/User_Guide.html",
    "title": "Weather or Not: Predicting The Unpredictable",
    "section": "",
    "text": "Special Thanks to Our Instructor: Dr. Kam Tin Seong\n\n\n\nThis dashboard offers a variety of visualization tools to analyze Singapore’s weather patterns.\nOur platform combines historical data analysis with forecasting capabilities to help you understand and predict weather patterns effectively.\n\nInteractive Visualizations: Explore weather patterns through dynamic charts and maps\n\nTime Series Analysis: Decompose and analyze weather trends\n\nWeather Forecasting: Predict future weather patterns using various models"
  },
  {
    "objectID": "ShinyApp/User_Guide.html#exploratory-analysis-line-chart",
    "href": "ShinyApp/User_Guide.html#exploratory-analysis-line-chart",
    "title": "User_Guide",
    "section": "",
    "text": "The Line Chart module helps you explore how a weather variable changes over time at a selected station. It’s especially useful for identifying long-term trends, seasonal cycles, and the effects of monsoon periods in Singapore.\n\n\n\n\nChoose a Variable\nUse the dropdown to select the weather variable you want to analyze. Options include:\n\nMean / Min / Max Temperature\n\nRainfall\n\nWind Speed (Mean / Max)\n\nPick a Station\nType or select from the list of available weather stations. For example, you can choose Changi (East), Newton, etc.\nSet the Time Resolution\nDecide how you want to group the data:\n\nDaily: for fine-grained fluctuations\n\nWeekly: for smoother patterns\n\nMonthly: best for observing seasonal trends\n\nSelect the Date Range\nUse the calendar input to define the period you want to analyze (e.g., 2019-01-01 to 2025-01-31).\nToggle Monsoon Periods (Optional)\nWant to see how monsoons affect weather? Check or uncheck the Show Monsoon Periods box under Display Options.\n\nLight blue = Northeast Monsoon (Dec to early Mar)\n\nLight green = Southwest Monsoon (Jun to Sep)\n\n\n\n\nClick “Update View”\nOnce you’ve set all your preferences, hit the Update View button to generate the chart.\n\n\n\nOn the right, a time series line chart shows how the selected variable (e.g., mean temperature) changes over time.\nIf monsoon display is enabled, colored bands will appear in the background to highlight the monsoon periods.\n\n\n\n\n\nBelow the chart, a summary statistics panel shows key stats for the selected station and variable:\n\nMinimum and Maximum\nQuartiles (Q1, Q2, Q3)\nMean\nStandard Deviation (SD)\n\n\n\n\n\n\nYou can click the “About Monsoon” panel at the top to learn more about Singapore’s seasonal weather patterns and how they may impact your analysis."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#exploratory-analysis-ridge-plot",
    "href": "ShinyApp/User_Guide.html#exploratory-analysis-ridge-plot",
    "title": "User_Guide",
    "section": "",
    "text": "The Ridge Plot module lets you compare the monthly distribution of a selected weather variable across multiple stations using visually appealing ridgeline plots. It’s a great way to spot seasonal trends and variations across different locations.\n\n\n\n\nChoose a Variable\nSelect Stations\nYou can only select up to 4 weather stations at once. This limit is intentionally set to keep the plot clear and readable.\n\nIf you select more than 4 stations, a warning will appear prompting you to reduce the number of selections.\n\n\nSet Time Resolution\n\nMonthly (default, y-axis is explicitly labeled with months to compare seasonal distributions)\n\nChoose a Date Range\nClick “Update View”\n\n\n\n\n\n\nClick the right tab : - A clean table summarizes key statistics by station, including:\n- Minimum,Quartiles,Median,Mean,Maximum\n\nYou can toggle between these two tabs any time to switch between visual and numeric summaries.\n\n\n\nIncluding too many stations on one ridgeline plot can make it hard to read. To ensure visual clarity and keep the plot user-friendly, we’ve limited the selection to a maximum of 4 stations at once. This helps users focus on meaningful comparisons without overwhelming the display."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#exploratory-analysis-geofacet",
    "href": "ShinyApp/User_Guide.html#exploratory-analysis-geofacet",
    "title": "User_Guide",
    "section": "",
    "text": "The Geofacet module is designed to help you compare weather trends across multiple stations in Singapore, using small multiples arranged by geography. It provides two tabs — one to view all stations at once, and another to focus on a selected subset.\n\n\n\n\n\nSelect Stations\nFrom the list, choose one or more weather stations to analyze. You can either:\n\nView all stations (left tab: All Stations)\nFocus on a few specific stations (right tab: Selected Stations) for clearer comparisons.\n\nChoose a Variable\nSet the Time Resolution\nPick a Date Range\nClick “Update View”\n\n\n\n\n\nA single line chart overlays the selected stations for direct comparison.\nThis view is helpful when you’re only interested in a few locations and want to analyze their trends side-by-side with greater visual clarity.\nA color legend on the right distinguishes each station."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#exploratory-analysis-isohyet-map",
    "href": "ShinyApp/User_Guide.html#exploratory-analysis-isohyet-map",
    "title": "User_Guide",
    "section": "",
    "text": "The Isohyet Map module lets you perform spatial interpolation to visualize how a weather variable (like temperature or rainfall) is distributed across Singapore.\n\n\n\n\n\nChoose a Variable\nSet Time Resolution\nPick a Date Range\nIDW Nmax (Groups) – Controls how many neighboring points are considered.\nInverse Distance Power – Controls how much nearby points influence the prediction.\n\n\n\nYou can leave the default settings or adjust them to experiment. If you’re not using IDW, you can skip this section.\n\n\n\nSelect Variogram Model\nChoose one of the options (e.g., Gau, Mat, Per).\nRun Model\n\n\n\n\n\n\n\n\n\n\n\nModel\nDescription\n\n\n\n\nGau\nProduces a smooth curve. Good when nearby locations are highly correlated.\n\n\nMat\nOffers flexible smoothness. Balances between Gaussian and exponential types. Often used in geostatistics.\n\n\nPer\nSuitable for seasonal or repeating patterns (e.g., weather cycles).\n\n\n\n\n🔍 Try different models and see how the Kriging map changes.\n\n\n\n\nIf you’re curious about how spatial interpolation works, just click the “About Spatial Interpolation” panel at the top — it gives a friendly explanation of IDW, Kriging, and Variograms."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#time-series-analysis-stl-decomposition",
    "href": "ShinyApp/User_Guide.html#time-series-analysis-stl-decomposition",
    "title": "Weather or Not: Predicting The Unpredictable",
    "section": "Time Series Analysis: STL Decomposition",
    "text": "Time Series Analysis: STL Decomposition\nThe STL Decomposition module helps you break down a time series into three components — Trend, Seasonal, and Remainder — so you can better understand long-term and seasonal behaviors in your weather data.\n\n\n\nHow to Use This Module (Step-by-Step)\n1. Select Variable\n2. Select Station\nPick a single station (e.g., Clementi) to focus the decomposition on.\n3. Set Time Resolution\n4. Choose Date Range\n5. After setting everything, hit “Run Model”\n\n\n\n\nSTL Decomposition Plot (Top Right)\nThis shows how your time series breaks down into:\n- Trend: Long-term movement of the variable\n- Seasonal: Repeating seasonal patterns (e.g., annual temperature cycle)\n- Remainder: What’s left over after removing trend and seasonality.\nYou’ll see these three components stacked clearly over time.\n\n\nCycle Plot by Month (Bottom Right)\nThis plot shows the seasonal pattern by month: - Each panel (Jan–Dec) shows how the variable fluctuates in that month across years. - Helps you identify which months are consistently higher or lower than the average. - The blue line in each panel represents the monthly average baseline.\n\n\n\n\n💡 Tip\nIf you’re not sure what STL means, click the “About STL Decomposition” panel — it gives a friendly explanation of each component!"
  },
  {
    "objectID": "ShinyApp/User_Guide.html#time-series-analysis-correlograms",
    "href": "ShinyApp/User_Guide.html#time-series-analysis-correlograms",
    "title": "User_Guide",
    "section": "",
    "text": "The Correlogram Analysis module helps you explore autocorrelation structures in your time series data. It provides tools to assess whether your series has trend or seasonality, and whether differencing is needed for modeling.\n\n\n\n1. Select Variable\n2. Select Station\n3. Set Time Resolution\n4. Choose Date Range\n5. Choose Plot Type\nSelect one of the three plot styles to focus on:\n- partial shows PACF & ACF (default)\n- scatter shows lag scatter plots (for visual correlation)\n- histogram shows the distribution of observed values\n6. Adjust Maximum Lag\nUse the slider to set how far into the past the autocorrelation should be checked (e.g., 24 months).\n7. After setting everything, hit “ Run Analysis”\n\n\n\n\n\nTime Series Line Plot of the selected variable\n\nACF (Autocorrelation Function) – measures how current values relate to past ones\n\nPACF (Partial Autocorrelation) – filters out indirect effects from intermediate lags\n\n\n\nA differenced time series that removes trend (using lag = 1)\n\nCorresponding ACF/PACF plots show whether autocorrelation is reduced\n\nHelps decide whether trend differencing is necessary\nA second round of differencing, targeting seasonality\n\nUsually done at lag = 12 (for monthly data)\n\nFinal ACF/PACF plots help check if the series is now close to white noise\n\n\n\n\n\n\nUse this module before model training to diagnose time series structure\nIf strong spikes appear in ACF/PACF, differencing may be required\nBlue dashed lines = significance threshold. Bars that exceed them are statistically significant\n\n\n\n\n\nIf you want to understand ACF/PACF better, open the About Correlogram Analysis panel at the top — it has a quick explanation."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#univariate-forecasting-model-training",
    "href": "ShinyApp/User_Guide.html#univariate-forecasting-model-training",
    "title": "User_Guide",
    "section": "",
    "text": "The Model Training module enables users to build and evaluate time series forecasting models using historical weather data. Users can select variables, define the training period, and choose from multiple Exponential Smoothing (ETS) and ARIMA-based models.\n\n💡 Tip\nIf you see spinning circles when the page loads — don’t worry!\nThat just means the dashboard is waiting for you to select at least one model and click Run Training. Once you do, results will appear on the right side of the screen.\n\n\n1. Select Variable\n2. Select Station\n3. Set Time Resolution\n4. Choose Date Range\n5. Model Selection\nA variety of univariate models are available for training:\n\n\n\n\n\n\n\nModel\nDescription\n\n\n\n\nETS-ANN\nSimple Exponential Smoothing — assumes no trend or seasonality\n\n\nETS-AAN\nHolt’s Linear Trend — accounts for a linear trend, but no seasonality\n\n\nETS-AAA\nHolt-Winters Additive — handles both trend and additive seasonality\n\n\nETS-MMM\nHolt-Winters Multiplicative — for multiplicative seasonal effects\n\n\nETS-MAM\nMultiplicative Holt-Winters with Additive Trend — mixed components\n\n\nETS-MMN\nMultiplicative Trend with No Seasonality — for growing or shrinking series\n\n\nAuto ETS\nAutomatically selects the best ETS model based on AIC/BIC\n\n\nAuto ARIMA\nAutomatically finds the best ARIMA model using statistical tests"
  },
  {
    "objectID": "ShinyApp/User_Guide.html#univariate-forecasting-model-forecasting",
    "href": "ShinyApp/User_Guide.html#univariate-forecasting-model-forecasting",
    "title": "User_Guide",
    "section": "",
    "text": "This module provides an end-to-end pipeline for training and evaluating time series forecasting models based on univariate inputs. Users can select weather variables (e.g., mean temperature) at a chosen station and generate short-term forecasts using various models.\n\n\n\n\nSelect Variable\nSelect Station\nSet Time Resolution\nSet Forecast Period\nUse the slider to select how many steps (months) you want to forecast, e.g., 12 or 24 months.\nSelect Models\n\nOnce everything is selected, click the Run Training button.\n\n💡 If you initially see three rotating loading rings — don’t worry!\nThe system is simply waiting for you to select a model and trigger the training process.\n\n\n\n\n\n\n\n\n\n\nModel Code\nDescription\n\n\n\n\nETS-ANN\nSimple exponential smoothing (no trend, no seasonality)\n\n\nETS-AAN\nHolt’s linear trend model\n\n\nETS-AAA\nHolt-Winters additive trend and seasonality\n\n\nETS-MMM\nHolt-Winters multiplicative trend and seasonality\n\n\nETS-MAM\nMultiplicative seasonality with additive trend\n\n\nETS-MMN\nMultiplicative trend only (no seasonality)\n\n\nAuto ETS\nAutomatically selects the best ETS model\n\n\nAuto ARIMA\nAutomatically identifies the optimal ARIMA configuration\n\n\n\n\n\n\n\nModel Training Plot (Top Right)\nVisualizes actual vs predicted values with 95% confidence intervals. Each selected model is color-coded.\nModel Evaluation Table (Bottom Center)\nShows AIC, BIC, and RMSE scores to help you compare models.\nResiduals Plot (Bottom Right)\nDisplays the residuals for each model to check whether errors are randomly distributed.\n\n\n\n\n\n\nForecast Plot (Top Right)\nShows the historical data and the forecasted values for the selected period, with confidence intervals shaded.\nForecast Model Parameters (Bottom Right)\nLists key parameters from the fitted models — including coefficients, standard errors, and p-values — to help interpret the models’ behavior."
  },
  {
    "objectID": "ShinyApp/User_Guide.html#about-the-dashboard",
    "href": "ShinyApp/User_Guide.html#about-the-dashboard",
    "title": "Weather or Not: Predicting The Unpredictable",
    "section": "",
    "text": "This dashboard offers a variety of visualization tools to analyze Singapore’s weather patterns.\nOur platform combines historical data analysis with forecasting capabilities to help you understand and predict weather patterns effectively.\n\nInteractive Visualizations: Explore weather patterns through dynamic charts and maps\n\nTime Series Analysis: Decompose and analyze weather trends\n\nWeather Forecasting: Predict future weather patterns using various models"
  },
  {
    "objectID": "Team/Meeting_Records.html",
    "href": "Team/Meeting_Records.html",
    "title": "ISSS608 Group 13 – Project Meeting Minutes",
    "section": "",
    "text": "Date: 07/03/2025\nAttendees: Doreen, Bingbing\n\n\n\n\nFinalize project topic and title\n\nConfirm data source\n\nOutline dashboard structure\n\nCreated GitHub repository and initialized Netlify website for team collaboration.\n\n\n\n\n\nDecided to use Singapore’s historical weather data (2019–2025) as the main dataset.\n\nFinalized the project title: Weather or Not – Predicting the Unpredictable\n\nBrainstormed key components to include across three analysis stages:\n\nExploratory Data Analysis (EDA):\n\nHistogram\n\nScatter Plot\n\nRidge Plot\n\nLine Chart\n\n\nConfirmatory Data Analysis (CDA):\n\nNormality Test\n\nParametric Test (e.g., t-test)\n\nNon-Parametric Test (e.g., Wilcoxon)\n\n\nForecasting:\n\nETS Models\n\nARIMA Models\n\n\n\nNarrowed focus to prioritize visual modules with decision-support value (EDA + Forecasting)\nCreated GitHub repo and Netlify website\n\nPublished project proposal: 🔗 Project Proposal\n\n\n\n\n\nDate: 05/03/2025\nTime: 8:00 – 9:00 PM\nIn Attendance: Doreen, Bingbing\n\n\n\nDownload and explore weather data from NEA\n\nPlan dashboard modules based on data availability\n\nAlign UI design and standardize style\n\nAssign responsibilities for Shiny modules\n\nConfirm project direction\n\n\n\n\n\nDecided to use official Singapore weather data from NEA (National Environment Agency), covering temperature, rainfall, and wind speed.\nDownloaded datasets and explored variable structures and formats.\nPlanned key dashboard modules: Line Chart, Ridge Plot, Geofacet, Isohyet Map, Correlograms and Forecasting.\nCreated GitHub repository and initialized Netlify website for team collaboration.\nProfessor Kam assisted us in refining our project direction and objectives.\nStandardized UI styling across modules to maintain a cohesive user experience.\n\n\n\n\n\n\n\nTask\nMember(s)\n\n\n\n\nData Download\nBingbing\n\n\nData Cleaning & Preparation\nBingbing, Doreen\n\n\nExploratory Data Analysis (Line, Ridge, Geofacet)\nBingbing\n\n\nEDA – Isohyet Map\nDoreen\n\n\nTime Series Analysis (STL, Correlograms)\nDoreen\n\n\nUnivariate Forecasting\nDoreen\n\n\n\n\n\n\n\n\nDate: 25/03/2025\nTime: 2:30 – 3:15 PM\nIn Attendance: Doreen, Bingbing\n\n\n\nIntegrate all Shiny modules\n\nPrepare poster and finalize visuals\n\nFinalize user guide content\n\n\n\n\n\nCombined all modules into a single Shiny dashboard\n\nEnsured visual consistency across modules\n\nUser guide writing delegated per module and to be completed before final deployment on 06/04/2025\n\n\nThese records summarize Group 13’s key project coordination meetings for the ISSS608 dashboard: “Weather or Not – Predicting the Unpredictable”."
  },
  {
    "objectID": "Team/Meeting_Records.html#project-meeting-1-topic-finalization-setup",
    "href": "Team/Meeting_Records.html#project-meeting-1-topic-finalization-setup",
    "title": "ISSS608 Group 13 – Project Meeting Minutes",
    "section": "",
    "text": "Date: 23/03/2025\nTime: 8:30 – 9:15 PM\nIn Attendance: Doreen, Bingbing\n\n\n\nFinalize project topic and title\n\nConfirm data source\n\nOutline initial dashboard structure\n\nCreated GitHub repository and initialized Netlify website for team collaboration.\n\n\n\n\n\nDecided to use Singapore’s historical weather data (2019–2025) as the main dataset.\n\nFinalized the project title: Weather or Not – Predicting the Unpredictable.\n\nDiscussed and outlined the main dashboard modules:\n\nLine Chart\n\nRidge Plot\n\nGeofacet\n\nCorrelograms\n\nIsohyet Map\n\nUnivariate Forecasting\n\nCreated a shared GitHub repository for collaboration\n\nLaunched the Netlify site and published the project proposal:\n🔗 Project Proposal"
  },
  {
    "objectID": "Team/Meeting_Records.html#project-meeting-2-data-download-cleaning-module-planning",
    "href": "Team/Meeting_Records.html#project-meeting-2-data-download-cleaning-module-planning",
    "title": "ISSS608 Group 13 – Project Meeting Minutes",
    "section": "",
    "text": "Date: 05/03/2025\nTime: 8:00 – 9:00 PM\nIn Attendance: Doreen, Bingbing\n\n\n\nDownload and explore weather data from NEA\n\nPlan dashboard modules based on data availability\n\nAlign UI design and standardize style\n\nAssign responsibilities for Shiny modules\n\nConfirm project direction\n\n\n\n\n\nDecided to use official Singapore weather data from NEA (National Environment Agency), covering temperature, rainfall, and wind speed.\nDownloaded datasets and explored variable structures and formats.\nPlanned key dashboard modules: Line Chart, Ridge Plot, Geofacet, Isohyet Map, Correlograms and Forecasting.\nCreated GitHub repository and initialized Netlify website for team collaboration.\nProfessor Kam assisted us in refining our project direction and objectives.\nStandardized UI styling across modules to maintain a cohesive user experience.\n\n\n\n\n\n\n\nTask\nMember(s)\n\n\n\n\nData Download\nBingbing\n\n\nData Cleaning & Preparation\nBingbing, Doreen\n\n\nExploratory Data Analysis (Line, Ridge, Geofacet)\nBingbing\n\n\nEDA – Isohyet Map\nDoreen\n\n\nTime Series Analysis (STL, Correlograms)\nDoreen\n\n\nUnivariate Forecasting\nDoreen"
  },
  {
    "objectID": "Team/Meeting_Records.html#project-meeting-3-final-integration-poster-preparation",
    "href": "Team/Meeting_Records.html#project-meeting-3-final-integration-poster-preparation",
    "title": "ISSS608 Group 13 – Project Meeting Minutes",
    "section": "",
    "text": "Date: 25/03/2025\nTime: 2:30 – 3:15 PM\nIn Attendance: Doreen, Bingbing\n\n\n\nIntegrate all Shiny modules\n\nPrepare poster and finalize visuals\n\nFinalize user guide content\n\n\n\n\n\nCombined all modules into a single Shiny dashboard\n\nEnsured visual consistency across modules\n\nUser guide writing delegated per module and to be completed before final deployment on 06/04/2025\n\n\nThese records summarize Group 13’s key project coordination meetings for the ISSS608 dashboard: “Weather or Not – Predicting the Unpredictable”."
  },
  {
    "objectID": "Overview/Overview.html",
    "href": "Overview/Overview.html",
    "title": "Overview of the Project",
    "section": "",
    "text": "🌦️ Overview of the Project\nOur project, titled Weather or Not – Predicting the Unpredictable, focuses on analyzing and forecasting weather patterns in Singapore using interactive visualizations and time series models.\nWe used official data from the National Environment Agency (NEA), covering the years 2019 to 2025, and built an R Shiny dashboard that offers a suite of tools for exploratory analysis, time series decomposition, and univariate forecasting.\nThe dashboard consists of the following key modules:\n\nLine Chart: Visualize variable trends over time and overlay monsoon periods.\nRidge Plot: Compare seasonal distributions across multiple stations.\nGeofacet: Examine spatial weather trends with geographically arranged line charts.\nIsohyet Map: Perform spatial interpolation of rainfall or temperature.\nCorrelograms: Analyze autocorrelation and guide differencing decisions.\nUnivariate Forecasting: Train and evaluate ETS and ARIMA models, and forecast future values.\n\nOur platform emphasizes clarity, consistency, and interactivity, and aims to serve as a practical tool for stakeholders needing reliable weather insights for operational planning."
  }
]