[
  {
    "objectID": "ShinyApp/Prototype_test.html",
    "href": "ShinyApp/Prototype_test.html",
    "title": "Prototype Testing",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse,readxl)\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_PLNG_AREA_WEB_PL\")\n\nReading layer `MP14_PLNG_AREA_WEB_PL' from data source \n  `/Users/johsuan/johsuanh/ISSS608-VAA-GroupProject/ShinyApp/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 55 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nage &lt;- read_csv(\"data/ResidentPopulationbyPlanningAreaSubzoneofResidenceAgeGroupandFloorAreaofResidenceCensusofPopulation2020.csv\")\n\nRows: 388 Columns: 121\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (121): Number, Total1_Total, Total1_0_4, Total1_5_9, Total1_10_14, Total...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nincome &lt;- read_excel(\"data/ResidentHouseholdsbyPlanningAreaofResidenceandMonthlyHouseholdIncomefromWorkCensusOfPopulation2020.xlsx\",sheet = \"sheet1\",range=\"A11:U43\")\n\n\nage &lt;- age %&gt;%\n  filter(grepl(\"Total\", Number, ignore.case = TRUE)) %&gt;%  \n  select(1:21) %&gt;%\n  replace(. == \"-\", NA) %&gt;%\n  mutate(across(2:21, as.numeric)) %&gt;%\n  mutate(Aged = rowSums(select(., 16:21), na.rm = TRUE)) %&gt;%\n  mutate(PA = sub(\" - Total.*\", \"\", Number))%&gt;%\n  select(c(\"PA\",\"Aged\",\"Total1_Total\"))%&gt;%\n  mutate(`Aged%` = round(Aged/Total1_Total*100,0),\n         PA = toupper(PA))\n\n\nage &lt;- left_join(mpsz,age,by = c(\"PLN_AREA_N\" = \"PA\"))\n\n\nincome &lt;- income %&gt;%\n  mutate(across(2:21, as.numeric))\nincome_proportion &lt;- income %&gt;%\n  mutate(across(3:21, ~ round(. / income[[2]] * 100, 2))) %&gt;%\n  mutate(`LowerIncome%`=rowSums(select(.,3:6), na.rm = TRUE))\nlow_income &lt;- income_proportion %&gt;%\n  select(c(`Planning Area of Residence`,`LowerIncome%`))%&gt;%\n  mutate(`Planning Area of Residence` = toupper(`Planning Area of Residence`))\n\n\nlow_income &lt;- left_join(mpsz,low_income,by = c(\"PLN_AREA_N\" = \"Planning Area of Residence\"))\n\n\n# Ensure both layers have the same CRS\nlow_income &lt;- st_transform(low_income, st_crs(age))\n\n# Set the tmap mode to view (interactive)\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n# Create the map with multiple layers\ntm_shape(age) +\n  tm_fill(col = \"Aged%\", \n          palette = \"Blues\", \n          title = \"Aged Population(%)\",\n          alpha = 0.9,\n          style = \"quantile\") +\n  tm_borders(col = \"white\", lwd = 0.5, alpha = 0.5) +\ntm_shape(low_income) + \n  tm_fill(col = \"LowerIncome%\", \n          palette = \"YlOrRd\", \n          title = \"IncomeBelow:3000(%)\", \n          style = \"quantile\",\n          n = 5,\n          alpha = 0.6) +\n  tm_borders(col = \"darkgrey\", lwd = 0.5, alpha = 0.5) +\ntm_basemap(server = \"CartoDB.Positron\") +\ntm_layout(title = \"Aged and Low-Income Population Across Singapore\", \n          legend.outside = TRUE,\n          legend.outside.position = \"right\")\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(title = )`[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"Multiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"YlOrRd\" is named\n\"brewer.yl_or_rd\"Multiple palettes called \"yl_or_rd\" found: \"brewer.yl_or_rd\", \"matplotlib.yl_or_rd\". The first one, \"brewer.yl_or_rd\", is returned.\n\n\n\n\n\n\n\n\n\npacman::p_load(ggdist,ggridges,lubridate,knitr)\n\n\nstation&lt;-read_csv(\"data/Singapore_daily_records.csv\")\n\nRows: 22230 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): station\ndbl (12): year, month, day, daily_rainfall_total_mm, highest_30_min_rainfall...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npacman::p_load(dplyr, lubridate)\n\n#station &lt;- station %&gt;%mutate(across(where(is.character), as.numeric)) \n\nstr(station)\n\nspc_tbl_ [22,230 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ station                    : chr [1:22230] \"Paya Lebar\" \"Paya Lebar\" \"Paya Lebar\" \"Paya Lebar\" ...\n $ year                       : num [1:22230] 2019 2019 2019 2019 2019 ...\n $ month                      : num [1:22230] 1 1 1 1 1 1 1 1 1 1 ...\n $ day                        : num [1:22230] 1 2 3 4 5 6 7 8 9 10 ...\n $ daily_rainfall_total_mm    : num [1:22230] 0 0 0 0 6.2 0 0 14.9 0 0 ...\n $ highest_30_min_rainfall_mm : num [1:22230] NA NA NA NA NA NA NA NA NA NA ...\n $ highest_60_min_rainfall_mm : num [1:22230] NA NA NA NA NA NA NA NA NA NA ...\n $ highest_120_min_rainfall_mm: num [1:22230] NA NA NA NA NA NA NA NA NA NA ...\n $ mean_temperature_c         : num [1:22230] 29.5 30 30.3 30.4 29 29.1 29.4 28.6 29.1 29.2 ...\n $ maximum_temperature_c      : num [1:22230] 34.2 33.8 33.1 33.5 34 32.7 33.1 31.6 32.7 33 ...\n $ minimum_temperature_c      : num [1:22230] 26.1 25.8 26.7 26.9 26 26.2 26 26 25.8 25.3 ...\n $ mean_wind_speed_km_h       : num [1:22230] 11.9 13 15.8 11.2 7.2 15.8 16.6 12.6 16.9 16.6 ...\n $ max_wind_speed_km_h        : num [1:22230] 42.5 46.4 48.2 35.3 31.3 38.9 42.5 33.5 42.5 42.5 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   station = col_character(),\n  ..   year = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   daily_rainfall_total_mm = col_double(),\n  ..   highest_30_min_rainfall_mm = col_double(),\n  ..   highest_60_min_rainfall_mm = col_double(),\n  ..   highest_120_min_rainfall_mm = col_double(),\n  ..   mean_temperature_c = col_double(),\n  ..   maximum_temperature_c = col_double(),\n  ..   minimum_temperature_c = col_double(),\n  ..   mean_wind_speed_km_h = col_double(),\n  ..   max_wind_speed_km_h = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nggplot(station, \n       aes(x = mean_temperature_c, y = station, fill = station)) +\n  geom_density_ridges(\n    scale = 2, \n    rel_min_height = 0.01, \n    alpha = 0.5\n  ) +\n  labs(title = \"Distribution of Temperature Across Stations\",\n       x = \"Mean Temperature (°C)\", \n       y = \"Station\") +\n  theme(\n    panel.background = element_rect(fill = \"#f3f1e9\"),\n    plot.background = element_rect(fill = \"#f3f1e9\", color = NA),\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\")\n  )\n\nPicking joint bandwidth of 0.263\n\n\nWarning: Removed 17484 rows containing non-finite outside the scale range\n(`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n\nggplot(station, \n       aes(x = station,y = mean_temperature_c)) +\n  stat_halfeye(\n               alpha = 0.5,\n               adjust = 0.5,\n               justification = -0.1,\n               .width = 0,\n               fill = \"#8AA4FF\")+\n  geom_boxplot(width = 0.10,\n               outlier.shape = NA,\n               color=\"grey50\")+\n  labs(title =\"Distribution of Mean Temperature Across Stations\",\n       x = \"\", y=\"Mean Temperature\")+\n  coord_flip() +\n  theme(panel.background = element_rect(fill = \"#ffffff\"),\n        plot.background = element_rect(fill = \"#ffffff\",color = NA),\n        legend.position = 'none',\n        plot.title = element_text(face = \"bold\",size=13,hjust=0.5))\n\nWarning: Removed 17484 rows containing missing values or values outside the scale range\n(`stat_slabinterval()`).\n\n\nWarning: Removed 17484 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nquartile_station_table &lt;- station %&gt;%\n  group_by(station) %&gt;%\n  summarize(\n    Min    = round(min(mean_temperature_c, na.rm = TRUE),2),\n    Q1     = round(quantile(mean_temperature_c, probs = 0.25, na.rm = TRUE),2),\n    Median = round(median(mean_temperature_c, na.rm = TRUE),2),\n    Mean   = round(mean(mean_temperature_c, na.rm = TRUE),2),\n    Q3     = round(quantile(mean_temperature_c, probs = 0.75, na.rm = TRUE),2),\n    Q4     = round(quantile(mean_temperature_c, probs = 1, na.rm = TRUE),2),\n    Max    = round(max(mean_temperature_c, na.rm = TRUE),2)\n  )\n\nkable(quartile_station_table)\n\n\n\n\nstation\nMin\nQ1\nMedian\nMean\nQ3\nQ4\nMax\n\n\n\n\nAdmiralty\n23.9\n27.3\n28.0\n27.98\n28.8\n30.1\n30.1\n\n\nAng Mo Kio\n23.7\n27.5\n28.2\n28.13\n29.0\n30.4\n30.4\n\n\nChangi\n24.1\n27.8\n28.4\n28.32\n29.1\n30.7\n30.7\n\n\nClementi\n23.8\n27.5\n28.1\n28.01\n28.7\n30.2\n30.2\n\n\nJurong (West)\n23.4\n27.1\n27.9\n27.93\n28.8\n30.8\n30.8\n\n\nMarina Barrage\n24.6\n28.3\n29.0\n28.90\n29.6\n30.8\n30.8\n\n\nNewton\n23.7\n27.5\n28.1\n27.94\n28.6\n29.9\n29.9\n\n\nPasir Panjang\n24.5\n28.0\n28.6\n28.53\n29.2\n30.6\n30.6\n\n\nPaya Lebar\n24.8\n28.2\n29.1\n28.91\n29.8\n31.7\n31.7\n\n\nTai Seng\n24.5\n28.2\n28.8\n28.75\n29.5\n31.0\n31.0\n\n\n\n\n\n\npacman::p_load(plotly,ggplot2,dplyr)\n\n# Change to \"all\" to display all stations\nselected_station &lt;- c(\"Changi\", \"Marina Barrage\",\"Ang Mo Kio\",\"Clementi\",\"Jurong (West)\",\"Paya Lebar\",\"Newton\",\"Pasir Panjang\",\"Tai Seng\",\"Admiralty\"\n)\n\n# Filter the data accordingly\nstation_data &lt;- if (\"all\" %in% selected_station) {\n  station\n} else {\n  station %&gt;% filter(station %in% selected_station)\n}\n\n# Create the plot using the filtered data\np &lt;- ggplot(data = station_data, \n            aes(x = mean_temperature_c,\n                y = daily_rainfall_total_mm, \n                color = station)) +\n  geom_point(size = 1, alpha = 0.7) +  \n  coord_cartesian(ylim = c(0, 150))+\n  theme_minimal() +\n  labs(x = \"Mean Temperature (°C)\", y = \"Daily Total Rainfall (mm)\") +\n  theme(\n    plot.background = element_rect(fill = \"white\", color = NA),\n    panel.background = element_rect(fill = \"white\"),\n    axis.title = element_text(size = 10, hjust = 0.5),\n    axis.text = element_text(size = 8),\n    legend.position = \"top\",\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  )\n\n\nggplotly(p)\n\n\n\n\n\n\ncolnames(station)\n\n [1] \"station\"                     \"year\"                       \n [3] \"month\"                       \"day\"                        \n [5] \"daily_rainfall_total_mm\"     \"highest_30_min_rainfall_mm\" \n [7] \"highest_60_min_rainfall_mm\"  \"highest_120_min_rainfall_mm\"\n [9] \"mean_temperature_c\"          \"maximum_temperature_c\"      \n[11] \"minimum_temperature_c\"       \"mean_wind_speed_km_h\"       \n[13] \"max_wind_speed_km_h\"        \n\n\n\n# Create the Date column\nstation &lt;- station %&gt;%\n  mutate(date = as.Date(paste(year, month, day, sep = \"-\"), format = \"%Y-%m-%d\"))\n\n# Filter only Changi site data\nchangi_data &lt;- subset(station, station == \"Marina Barrage\")\n\n# Drawing\nggplot(changi_data, aes(x = date, y = mean_wind_speed_km_h, color = station, group = station)) +\n  geom_line(linewidth = 1, alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Mean Wind Speed Over Time at Changi\",\n       x = \"Date\",\n       y = \"Mean Wind Speed (km/h)\") +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )"
  },
  {
    "objectID": "Team/Project_Proposal.html",
    "href": "Team/Project_Proposal.html",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "",
    "text": "Climate change poses significant challenges for Singapore’s urban environment and infrastructure. As a densely populated tropical country, Singapore faces particular vulnerability to rising temperatures, extreme rainfall, and changing weather patterns. These climate-related risks affect not just daily life, but also impact urban planning, public health, and economic activities.\nTo address this challenge, our team will develop an interactive analytics dashboard using R Shiny App to transform complex weather data into actionable insights. Through analysis of historical and real-time data from 10 AWS stations across Singapore, we aim to create a platform that helps the public better understand and respond to Singapore’s changing climate conditions through intuitive visualizations and forecasting models."
  },
  {
    "objectID": "Team/Project_Proposal.html#exploratory-data-analysis-eda",
    "href": "Team/Project_Proposal.html#exploratory-data-analysis-eda",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.1 Exploratory Data Analysis (EDA)",
    "text": "4.1 Exploratory Data Analysis (EDA)\nThrough an interactive Shiny App visualization, users can analyze patterns and explore relationships between temporal data, rainfall, temperature, wind speed, and geographical features.\nThe following visualization methods will be used in our exploratory data analysis:\n\nTime Series Analysis  \n\nLine Chart: Visualize daily, weekly, and monthly weather trends by station over time.\n\nSeasonal Monsoon Patterns: Highlight monsoon periods Northeast Monsoon (Dec–Mar), Southwest Monsoon (Jun–Sep) and Inter-monsoon (Apr–May, Oct–Nov) with different color, letting user observe weather differences across stations.\n\nRidge Plot: Show the distribution of daily, weekly, and monthly weather variations by station.\nGeofacet: Display weather data with station layouts reflecting their geographical positions. Use faceted line charts (for temperature) and histograms (for rainfall) to highlight seasonal variations.\n\n\n\nGeospatial Analysis\n\nIsoline Maps: Visualize weather patterns using isolines overlaid on station data with tmap, showing spatial gradients."
  },
  {
    "objectID": "Team/Project_Proposal.html#confirmatory-data-analysis-cda",
    "href": "Team/Project_Proposal.html#confirmatory-data-analysis-cda",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.2 Confirmatory Data Analysis (CDA)",
    "text": "4.2 Confirmatory Data Analysis (CDA)\nAfter EDA, user can apply the following statistical tests to confirm whether mean rainfall or temperature differs across stations:\n\nNormality Test\n\nShapiro-Wilk Test : check if the data follows a normal distribution, which will affect which statistical parameters to use in the analysis \n\n\n\nParametric Tests (comparing multiple groups)\n\nOne-way ANOVA test: Comparing mean rainfall or temperature across stations \nTwo-way ANOVA test: Comparing mean rainfall or temperature across both station and month \n\n\n\nNon-Parametric Tests (comparing multiple groups) \n\nKruskal-Wallis Test: Comparing median rainfall or temperature across stations or both station and month"
  },
  {
    "objectID": "Team/Project_Proposal.html#forecasting",
    "href": "Team/Project_Proposal.html#forecasting",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.3 Forecasting",
    "text": "4.3 Forecasting\n\nPlots\n\nACF & PCF plots : help users understand the autocorrelation in time series data and identify which lags might be useful for forecasting model. \nSTL plots: help decompose the time series into its seasonal, trend, and remainder components, providing insight into the structure of the data. \n\n\n\nForecasting Models\n\nARIMA Models:  \n\nAuto ARIMA: when there is a mix of trend and seasonal patterns with autocorrelation, user can use auto ARIMA, which automatically selects the best parameters (AR, I, MA) based on the data \nSTL ARIMA: when there are complex seasonality or non-linear trends in the data, user can choose this model for weather forecasting\n\nETS Models:  \n\nAuto ETS: user can choose this model if the data shows clear, stable trends or seasonal patterns with little noise"
  },
  {
    "objectID": "ShinyApp/data/Import by html/Import by html.html",
    "href": "ShinyApp/data/Import by html/Import by html.html",
    "title": "import data",
    "section": "",
    "text": "pacman::p_load(rvest,dplyr,stringr,purrr,readr,httr,tidyr,fs,janitor,tidyverse,knitr)\n\n\n# Set the data folder path\ndata_folder &lt;- \"data\"\n\n# Weather stations and their corresponding SXXX codes\nstations &lt;- c(\"Changi\" = \"S24\", \"Marina_Barrage\" = \"S108\", \"Ang_Mo_Kio\" = \"S109\",\n              \"Clementi\" = \"S50\", \"Jurong_West\" = \"S44\", \"Paya_Lebar\" = \"S06\",\n              \"Newton\" = \"S111\", \"Pasir_Panjang\" = \"S116\", \"Tai_Seng\" = \"S43\",\n              \"Admiralty\" = \"S104\")\n\n# Define the range of years and months to check (January 2019 to January 2025)\nyears &lt;- 2019:2025\nmonths &lt;- sprintf(\"%02d\", 1:12)  # Format as 01, 02, ..., 12\n\n# Generate the complete list of expected files\nexpected_files &lt;- expand.grid(Station = names(stations), Year = years, Month = months, stringsAsFactors = FALSE) %&gt;%\n  filter(!(Year == 2019 & Month &lt; \"01\"),  # Exclude months before January 2019\n         !(Year == 2025 & Month &gt; \"01\"))  # Exclude months after January 2025\n\n# Generate the correct file name format (DAILYDATA_SXXX_YYYYMM.csv)\nexpected_files &lt;- expected_files %&gt;%\n  mutate(File_Code = stations[Station],  # Get the corresponding SXXX code\n         File_Name = paste0(\"DAILYDATA_\", File_Code, \"_\", Year, Month, \".csv\"),\n         File_Path = file.path(data_folder, File_Name))\n\n# Get the list of actually downloaded files\ndownloaded_files &lt;- dir_ls(data_folder, glob = \"*.csv\") %&gt;% basename()\n\n# Mark which files have been downloaded\nexpected_files &lt;- expected_files %&gt;%\n  mutate(Downloaded = File_Name %in% downloaded_files)\n\n# Summarize the download status\nsummary_table &lt;- expected_files %&gt;%\n  group_by(Station) %&gt;%\n  summarise(\n    Total_Expected = n(),\n    Downloaded = sum(Downloaded),\n    Missing = Total_Expected - Downloaded\n  )\n\n# Identify missing files\nmissing_files &lt;- expected_files %&gt;%\n  filter(!Downloaded) %&gt;%\n  select(Station, Year, Month, File_Name)\n\n# Print the list of missing files if any\nif (nrow(missing_files) &gt; 0) {\n  print(\"🚨 List of missing files:\")\n  print(missing_files)\n} else {\n  cat(\"🎉 All data downloaded successfully, no missing files!\\n\")\n}\n\n🎉 All data downloaded successfully, no missing files!\n\n# Display data download statistics\nprint(\"📊 Data download statistics:\")\n\n[1] \"📊 Data download statistics:\"\n\nprint(summary_table)\n\n# A tibble: 10 × 4\n   Station        Total_Expected Downloaded Missing\n   &lt;chr&gt;                   &lt;int&gt;      &lt;int&gt;   &lt;int&gt;\n 1 Admiralty                  73         73       0\n 2 Ang_Mo_Kio                 73         73       0\n 3 Changi                     73         73       0\n 4 Clementi                   73         73       0\n 5 Jurong_West                73         73       0\n 6 Marina_Barrage             73         73       0\n 7 Newton                     73         73       0\n 8 Pasir_Panjang              73         73       0\n 9 Paya_Lebar                 73         73       0\n10 Tai_Seng                   73         73       0\n\n\n\n# Set the data folder path\ndata_folder &lt;- \"data\"\n\n# Get the list of all CSV files\nfilenames &lt;- dir_ls(data_folder, glob = \"*.csv\")\n\n# Read all files, fix encoding, standardize column names, and remove duplicate columns\ncombined_data &lt;- filenames %&gt;%\n  map_df(~ read_csv(.x, \n                    locale = locale(encoding = \"latin1\"),  # Handle encoding issues\n                    col_types = cols(.default = \"character\"))  # Read all columns as character type initially\n  ) %&gt;%\n  janitor::clean_names()  # Standardize column names format\n\n# Select only the required columns\nselected_columns &lt;- c(\"station\", \"year\", \"month\", \"day\",\n                      \"daily_rainfall_total_mm\", \"highest_30_min_rainfall_mm\",\n                      \"highest_60_min_rainfall_mm\", \"highest_120_min_rainfall_mm\",\n                      \"mean_temperature_c\", \"maximum_temperature_c\",\n                      \"minimum_temperature_c\", \"mean_wind_speed_km_h\",\n                      \"max_wind_speed_km_h\")\n\n# Ensure the data contains only these columns and remove extra columns\ncombined_data &lt;- combined_data %&gt;%\n  select(any_of(selected_columns))  # `any_of()` prevents errors even if some columns are missing\n\n# Remove rows where 'station' is NA\ncombined_data &lt;- combined_data %&gt;%\n  filter(!is.na(station) & station != \"\")  # Remove NA and empty station names\n\n# Convert numeric columns to numeric type and clean missing values\nnumeric_cols &lt;- selected_columns[5:length(selected_columns)]  # Select numeric columns\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(across(all_of(numeric_cols), ~ as.numeric(str_replace(.x, \"[^0-9.-]\", \"\")), .names = \"clean_{.col}\")) %&gt;% # Clean data first\n  select(-all_of(numeric_cols)) %&gt;%  # Remove original columns\n  rename_with(~ str_remove(.x, \"clean_\"))  # Restore original column names\n\nWarning: There were 6 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(...)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 5 remaining warnings.\n\n# Save the merged dataset\nwrite_csv(combined_data, file = \"data/Singapore_daily_records.csv\")\n\n# Display data preview\nprint(\"✅ The merge is complete! Saved as: `Singapore_daily_records.csv`\")\n\n[1] \"✅ The merge is complete! Saved as: `Singapore_daily_records.csv`\"\n\nglimpse(combined_data)\n\nRows: 22,230\nColumns: 13\n$ station                     &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\", …\n$ year                        &lt;chr&gt; \"2019\", \"2019\", \"2019\", \"2019\", \"2019\", \"2…\n$ month                       &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ day                         &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9…\n$ daily_rainfall_total_mm     &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 6.2, 0.0, 0.0, 14.9, 0…\n$ highest_30_min_rainfall_mm  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ highest_60_min_rainfall_mm  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ highest_120_min_rainfall_mm &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ mean_temperature_c          &lt;dbl&gt; 29.5, 30.0, 30.3, 30.4, 29.0, 29.1, 29.4, …\n$ maximum_temperature_c       &lt;dbl&gt; 34.2, 33.8, 33.1, 33.5, 34.0, 32.7, 33.1, …\n$ minimum_temperature_c       &lt;dbl&gt; 26.1, 25.8, 26.7, 26.9, 26.0, 26.2, 26.0, …\n$ mean_wind_speed_km_h        &lt;dbl&gt; 11.9, 13.0, 15.8, 11.2, 7.2, 15.8, 16.6, 1…\n$ max_wind_speed_km_h         &lt;dbl&gt; 42.5, 46.4, 48.2, 35.3, 31.3, 38.9, 42.5, …"
  },
  {
    "objectID": "Team/Project_Proposal.html#co-variation-analysis",
    "href": "Team/Project_Proposal.html#co-variation-analysis",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.2 Co-variation Analysis",
    "text": "4.2 Co-variation Analysis\nAfter EDA, user can apply the following statistical tests to confirm whether rainfall, wind speed and temperature exhibit correlation with each other:\n\nCross-Correlation Function: Measures how two time series are correlated at different time lags. Helps identify lead-lag relationships, like “does a drop in temperature precede heavy rainfall?”\nCointegration Analysis: Tests if two time series move together in the long run despite short-term fluctuations, using the urca package."
  },
  {
    "objectID": "Team/Project_Proposal.html#exploratory-data-analysis",
    "href": "Team/Project_Proposal.html#exploratory-data-analysis",
    "title": "Project Proposal: Wheather or Not – Predicting the Unpredictable",
    "section": "4.1 Exploratory Data Analysis",
    "text": "4.1 Exploratory Data Analysis\nThrough an interactive Shiny App visualization, users can analyze patterns and explore relationships between temporal data, rainfall, temperature, wind speed, and geographical features.\nThe following visualization methods will be used in our exploratory data analysis:\n\nTime Series Analysis  \n\nLine Chart: Visualize daily, weekly, and monthly weather trends by station over time.\n\nSeasonal Monsoon Patterns: Highlight monsoon periods Northeast Monsoon (Dec–Mar), Southwest Monsoon (Jun–Sep) and Inter-monsoon (Apr–May, Oct–Nov) with different color, letting user observe weather differences across stations.\n\nRidge Plot: Show the distribution of daily, weekly, and monthly weather variations by station.\nGeofacet: Display weather data with station layouts reflecting their geographical positions. Use faceted line charts (for temperature) and histograms (for rainfall) to highlight seasonal variations.\n\n\n\nGeospatial Analysis\n\nIsoline Maps: Visualize weather patterns using isolines overlaid on station data with tmap, showing spatial gradients."
  }
]